{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e30dba4",
   "metadata": {},
   "source": [
    "# AI Clinique #15 : Recommender Systems\n",
    "\n",
    "- __Date__: 09-12-2021\n",
    "- __Presentator__: Nicolas Clavel\n",
    "- __Datasets__: For this hands-on, we will be using the following open source datasets\n",
    "    - Movie Lens Dataset accessible here: https://grouplens.org/datasets/movielens/latest/\n",
    "    - The movie database: https://www.kaggle.com/tmdb/tmdb-movie-metadata?select=tmdb_5000_movies.csv\n",
    "- __Packages__: pip install -r requirements.txt\n",
    "- __Documentation__:\n",
    "    - Interesting Github: https://github.com/rposhala/Recommender-System-on-MovieLens-dataset#content-based-recommender-system\n",
    "    - Scikit-surprise: http://surprise.readthedocs.io/en/stable/getting_started.html\n",
    "    - Matrix Factorization from scratch: https://towardsdatascience.com/recommendation-system-matrix-factorization-d61978660b4b\n",
    "    - Content-based filtering Kaggle: https://www.kaggle.com/ibtesama/getting-started-with-a-movie-recommendation-system/notebook\n",
    "- __Citation__:  \n",
    "Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e2392",
   "metadata": {},
   "source": [
    "## Recommender Systems\n",
    "The objective of a Recommender System is to __recommend relevant items for users__, based on their preference, history consumption...  \n",
    "We see the use of recommendation systems all around us. These systems are personalizing our web experience, telling us what to buy (Amazon), which movies to watch (Netflix), whom to be friends with (Facebook), which songs to listen (Spotify) etc.  \n",
    "Recommender systems typically produce a list of recommendations and there are few ways in which it can be done.  \n",
    "Two of the most popular ways are – through __collaborative filtering__ or through __content-based filtering__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af510b8a",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "- __1. Presentation of the Movie Lens dataset__\n",
    "- __2. Collaborative filtering__\n",
    "- __3. Content based filtering__\n",
    "- __4. Simple recommender system__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb9a66",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64903063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import SVD, NMF, KNNBasic, Reader, Dataset, accuracy\n",
    "from surprise.model_selection import cross_validate, GridSearchCV, train_test_split\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e90db",
   "metadata": {},
   "source": [
    "## 1. Presentation of the Movie Lens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6247dc",
   "metadata": {},
   "source": [
    "#### Movies file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movies\n",
    "movies = pd.read_csv('../input_data/ml-latest-small/movies.csv', low_memory=False)\n",
    "\n",
    "# Figures\n",
    "print(f'Nb of rows in the movies file: {len(movies)}')\n",
    "print(f'Columns of the movies file: {movies.columns.values}')\n",
    "\n",
    "# Print the first three rows\n",
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8342f795",
   "metadata": {},
   "source": [
    "#### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eed868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings\n",
    "ratings = pd.read_csv('../input_data/ml-latest-small/ratings.csv', low_memory=False)\n",
    "\n",
    "# Figures\n",
    "print(f'Nb of rows in the ratings file: {len(ratings)}')\n",
    "print(f'Columns of the ratings file: {ratings.columns.values}')\n",
    "print(f'Min ratings: {min(ratings[\"rating\"])} Max ratings: {max(ratings[\"rating\"])}')\n",
    "print(f'Nb of movies: {len(ratings[\"movieId\"].unique())}')\n",
    "print(f'Nb of users: {len(ratings[\"userId\"].unique())}')\n",
    "\n",
    "# Print the first three rows\n",
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9714eb0",
   "metadata": {},
   "source": [
    "#### Check if nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b16202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Nb nans values in userId: {pd.isnull(ratings[\"userId\"]).any()}')\n",
    "print(f'Nb nans values in movieId: {pd.isnull(ratings[\"movieId\"]).any()}')\n",
    "print(f'Nb nans values in rating: {pd.isnull(ratings[\"rating\"]).any()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f419826",
   "metadata": {},
   "source": [
    "#### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tags\n",
    "tags = pd.read_csv('../input_data/ml-latest-small/tags.csv', low_memory=False)\n",
    "\n",
    "# Figures\n",
    "print(f'Nb of rows in the tags file: {len(tags)}')\n",
    "print(f'Columns of the tags file: {tags.columns.values}')\n",
    "\n",
    "# Print the first three rows\n",
    "tags.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f791fb",
   "metadata": {},
   "source": [
    "#### Datavizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=ratings, x=\"rating\", binwidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20ff2fb",
   "metadata": {},
   "source": [
    "#### Number of ratings by movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ratings[['movieId','userId']].groupby(['movieId']).agg(['count']).sort_values(('userId','count'),ascending=False)\n",
    " \n",
    "plt.figure(figsize=(10,4))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data=df[('userId', 'count')].values)\n",
    "plt.title(\"Number of ratings by movie movies\")\n",
    "plt.xlabel(\"Movie id\")\n",
    "plt.ylabel(\"Number of ratings\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c2c6c",
   "metadata": {},
   "source": [
    "#### Number of ratings by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bdaf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ratings[['movieId','userId']].groupby(['userId']).agg(['count']).sort_values(('movieId','count'),ascending=False)\n",
    " \n",
    "plt.figure(figsize=(10,4))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(data=df[('movieId', 'count')].values)\n",
    "plt.title(\"Rating frequency of users\")\n",
    "plt.xlabel(\"User id\")\n",
    "plt.ylabel(\"Number of ratings\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3656c7",
   "metadata": {},
   "source": [
    "#### User-Item interaction matrix\n",
    "For top 15th rated users and items for vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b60dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 15\n",
    "g = ratings.groupby('userId')['rating'].count()\n",
    "topg = g.sort_values(ascending = False)[:top]\n",
    "\n",
    "i = ratings.groupby('movieId')['rating'].count()\n",
    "topi = i.sort_values(ascending = False)[:top]\n",
    "\n",
    "# gettings ratings of top users and top items\n",
    "join_top_users = ratings.join(topg, on='userId', how = 'inner', rsuffix='_r')\n",
    "join_top_movies_and_users = join_top_users.join(topi, on='movieId', how = 'inner', rsuffix = '_r')\n",
    "\n",
    "pd.crosstab(join_top_movies_and_users.userId, join_top_movies_and_users.movieId,\n",
    "            join_top_movies_and_users.rating, aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4e3a96",
   "metadata": {},
   "source": [
    "#### Measure of sparsity (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54918a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movies = len(ratings[\"movieId\"].unique())\n",
    "unique_users = len(ratings[\"userId\"].unique())\n",
    "total_ratings = unique_users * unique_movies\n",
    "rating_present = ratings.shape[0]\n",
    "\n",
    "ratings_not_provided = total_ratings - rating_present \n",
    "\n",
    "print(\"sparsity of user-item matrix is :\")\n",
    "print(ratings_not_provided / total_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e3858c",
   "metadata": {},
   "source": [
    "#### Users-items top 500 users, top 1000 movies\n",
    "This is done to limit matrix sparsity (for collaborative filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94468047",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_users = 500\n",
    "g = ratings.groupby('userId')['rating'].count()\n",
    "topg = g.sort_values(ascending = False)[:top_users]\n",
    "\n",
    "top_movies = 1000\n",
    "i = ratings.groupby('movieId')['rating'].count()\n",
    "topi = i.sort_values(ascending = False)[:top_movies]\n",
    "\n",
    "# gettings ratings of top users and top items\n",
    "join_top_users = ratings.join(topg, on='userId', how = 'inner', rsuffix='_r')\n",
    "join_top_movies_and_users = join_top_users.join(topi, on='movieId', how = 'inner', rsuffix = '_r')\n",
    "\n",
    "user_movie_matrix = pd.crosstab(join_top_movies_and_users.userId, join_top_movies_and_users.movieId,\n",
    "                                join_top_movies_and_users.rating, aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_matrix.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526794c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nb of users:')\n",
    "print(len(user_movie_matrix))\n",
    "\n",
    "print('Nb of movies:')\n",
    "print(len(user_movie_matrix.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sparsity:')\n",
    "print(user_movie_matrix.isna().sum().sum() / float(len(user_movie_matrix) * len(user_movie_matrix.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0725c94",
   "metadata": {},
   "source": [
    "## 2. Collaborative filtering\n",
    "__Collaborative filtering__ is based on the assumption that people who agreed in the past will agree in the future, and that they will like similar kinds of items as they liked in the past.  \n",
    "It uses __similarities between users behaviours__ to provide recommendations, there is no need of knowledge/features required.  \n",
    "There are two types of collaborative filtering:\n",
    "- __Memory based__\n",
    "- __Model based__  \n",
    "\n",
    "The key difference is that we __are not learning any parameter__ using gradient descent (or any other optimization algorithm) in the memory-based."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f0b1e",
   "metadata": {},
   "source": [
    "### 2.1. Matrix Factorization (Model based)\n",
    "__Matrix Factorization__ is denoted as methods that decompose a rating matrix for collaborative filtering.  \n",
    "The __user-item interaction matrice__ lists __users and items in rows and columns__, respectively.  \n",
    "The __ratings of user i on movie j__ is located in __cell(i, j)__ (the cell is empty if no ratings exist yet).  \n",
    "Documentation: https://developers.google.com/machine-learning/recommendation/collaborative/matrix  \n",
    "Matrix factorization from scratch: https://towardsdatascience.com/recommendation-system-matrix-factorization-d61978660b4b  \n",
    "Scikit-surprise doc: https://surprise.readthedocs.io/en/stable/matrix_factorization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='../input_data/matrix_facto_illustration.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18d414",
   "metadata": {},
   "source": [
    "#### Datapreparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed621f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = ratings[['movieId', 'userId', 'rating']]\n",
    "\n",
    "# The Reader class is used to parse a file containing ratings.\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# The columns must correspond to userId, itemId and ratings (in that order).\n",
    "dataset_ratings = Dataset.load_from_df(df_ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split dataset between train and test set\n",
    "train, test = train_test_split(dataset_ratings, test_size=.20, random_state=2)\n",
    "# As if we remove some cells of the user-item matrix to put them in the set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d1391",
   "metadata": {},
   "source": [
    "#### NMF: Non-negative Matrix Factorization\n",
    "Documentation: https://en.wikipedia.org/wiki/Non-negative_matrix_factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd973f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of latents factors\n",
    "n_factors=13\n",
    "\n",
    "# NMF model\n",
    "nmf = NMF(n_factors=n_factors)\n",
    "\n",
    "# Train the algorithm on the train set, and predict ratings for the test set\n",
    "nmf.fit(train)\n",
    "preds = nmf.test(test)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(preds)\n",
    "\n",
    "# To dataframe\n",
    "df_preds = pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b93ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e246edc",
   "metadata": {},
   "source": [
    "#### Make a prediction on a user and movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12efa234",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 1  # raw user id (as in the ratings file)\n",
    "iid = 2  # raw item id (as in the ratings file)\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = nmf.predict(uid, iid, verbose=True)  # we can also pass the real value if it is filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ae3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = nmf.predict(uid, iid, r_ui=0.5, verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d031c78",
   "metadata": {},
   "source": [
    "#### First conclusion:\n",
    "- The mean error (RMSE) seems pretty correct\n",
    "- But how to choose the number of factors ? => Using a grid-search on cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdde9ac",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use movielens-100K\n",
    "nmf = NMF()\n",
    "param_grid = {'n_factors': [12, 13, 14]}\n",
    "gs_nmf = GridSearchCV(NMF, param_grid, measures=['rmse'], cv=3)\n",
    "\n",
    "gs_nmf.fit(dataset_ratings)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs_nmf.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs_nmf.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f0e1c",
   "metadata": {},
   "source": [
    "#### SVD: Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62500373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD model\n",
    "svd = SVD()\n",
    "\n",
    "# Train the algorithm on the train set, and predict ratings for the test set\n",
    "svd.fit(train)\n",
    "preds_svd = svd.test(test)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(preds_svd)\n",
    "\n",
    "# To dataframe\n",
    "df_preds_svd = pd.DataFrame(preds_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fc12a",
   "metadata": {},
   "source": [
    "### 2.2. k Nearest Neighbour\n",
    "__K-nearest neighbor__ finds the k most similar items to a particular instance based on a given distance metric.  \n",
    "It can be used for classification (voting of the k-nearest neighbors) or regression (average values of the k-nearest neighbors).  \n",
    "In this my model, I used to __cosine similarity__ as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='../input_data/knn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f21ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 20\n",
    "metric = 'cosine'\n",
    "model_knn = NearestNeighbors(metric=metric, n_neighbors=n_neighbors, n_jobs=-1)\n",
    "index_user_to_predict_k_movies = 0 # we are going to predict for the first user\n",
    "top_k_movies = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nan values in empty scores (it does not impact cosine)\n",
    "user_movie_matrix_filled = user_movie_matrix.fillna(0)\n",
    "\n",
    "# train knn\n",
    "model_knn.fit(user_movie_matrix_filled)\n",
    "\n",
    "# Get similar users distances and indexes\n",
    "user_to_predict_k_movies = user_movie_matrix_filled.iloc[index_user_to_predict_k_movies,:].values.reshape(1,-1)\n",
    "distances, indices_similar_users = model_knn.kneighbors(user_to_predict_k_movies)\n",
    "distances = distances.flatten()\n",
    "indices_similar_users = indices_similar_users.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b750db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking average scores for these users (excluding zero because no score)\n",
    "similar_users = user_movie_matrix[user_movie_matrix.index.isin(indices_similar_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_scores_similar_users = np.nanmean(similar_users, axis=0) # compute mean score without taking into account nan\n",
    "movies_scores_similar_users = np.nan_to_num(movies_scores_similar_users) # than if only nan => put 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba32796",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_scores_similar_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16950b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies = []\n",
    "\n",
    "while len(top_movies) <= top_k_movies:\n",
    "    # Get index of the movie with the max score\n",
    "    max_value_index = movies_scores_similar_users.argmax()\n",
    "    \n",
    "    # Adding the movie with the highest score to the top list\n",
    "    top_movies.append(max_value_index)\n",
    "    \n",
    "    # Removing this index in the movies\n",
    "    movies_scores_similar_users = np.delete(movies_scores_similar_users, max_value_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies\n",
    "# there is still the need to remove movies that the user 0 have already watched, we can integrate it in the whil loop upper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21905866",
   "metadata": {},
   "source": [
    "#### Pros\n",
    "- __No domain knowledge necessary__: It does not need any information regarding the movies (genres, author...) , and any \"understanding\" of the movie itself \n",
    "- __Serendipity__ : The user can __discover new interests__ (because not featured based)\n",
    "\n",
    "#### Cons\n",
    "- __Cold start__: For a new user or item, there isn't enough data to make accurate recommendations. \n",
    "- __Scalability__: There are millions of users and products in many of the environments in which these systems make recommendations. Thus, a large amount of computation power is often necessary to calculate recommendations.\n",
    "- __Sparsity__: The number of items sold on major e-commerce sites is extremely large. The most active users will only have rated a small subset of the overall database. Thus, even the most popular items have very few ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f24bf6",
   "metadata": {},
   "source": [
    "## 3. Content-based Filtering\n",
    "__Content-Based Filtering__ is used to produce items recommendation based on items’ and/or users characteristics.  \n",
    "In these types of systems, the __descriptive attributes of items/users are used__ to make recommendations. The term “content” refers to these descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.iloc[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff03bf",
   "metadata": {},
   "source": [
    "#### TF-IdF : Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b72f8",
   "metadata": {},
   "source": [
    "We need to __convert the word vector__ into a __numerical representation__ We will use __Term Frequency-Inverse Document Frequency (TF-IDF)__ vectors for each overview.\n",
    "\n",
    "It is the __relative frequency of a word in a document__ (so here, a cell) and is given as (term instances/total instances). Inverse Document Frequency is the relative count of documents containing the term, given as log( 1 / number of documents/documents with term) The overall importance of each word to the documents in which they appear is equal to TF * IDF.  \n",
    "  \n",
    "For term Drama (for instance):\n",
    "- Cell with Crime|Drama => TF = 0.5\n",
    "- Log ratio of cells containing Drama => IDF = Log(1 / (200 cells/1000 total cells))\n",
    "TDF x IDF = 0.5 x log(5) = 0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6885f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "movies['genres'] = movies['genres'].apply(lambda x: x.replace('|', ' ').replace('-', ''))\n",
    "\n",
    "# tfidf matrix\n",
    "tfidf_matrix = tfidf.fit_transform(movies['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5295f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51876c",
   "metadata": {},
   "source": [
    "(9742, 21)  means that here are 21 different words are used to describe a 9742 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1811f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311798ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b61b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity\n",
    "cosin_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Put it in a Pandas Series\n",
    "index_of_movies = pd.Series(movies.index, index=movies['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosin_sim=cosin_sim, top_k=10):\n",
    "    \n",
    "    idx_of_title = index_of_movies[title]\n",
    "    \n",
    "    similarity_scores = list(enumerate(cosin_sim[idx_of_title]))\n",
    "    \n",
    "    # sorting of movies idx based on similarity score\n",
    "    similarity_scores = sorted(similarity_scores, key = lambda x:x[1], reverse = True)\n",
    "    \n",
    "    # get top k\n",
    "    similarity_scores = similarity_scores[0:top_k]\n",
    "    movies_idx = [i[0] for i in similarity_scores]\n",
    "    \n",
    "    return movies.iloc[movies_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23ef55",
   "metadata": {},
   "source": [
    "#### Make recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations(title='Dangerous Minds (1995)', cosin_sim=cosin_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef178c",
   "metadata": {},
   "source": [
    "This is not very efficient as all the movies with the same genre would have the same similarity score...  \n",
    "Let's try with another dataset with more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aff535",
   "metadata": {},
   "source": [
    "#### Content-based filtering based on movie overview description\n",
    "https://www.kaggle.com/tmdb/tmdb-movie-metadata?select=tmdb_5000_movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52693d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_lmdb = pd.read_csv('../input_data/tmdb_5000_movies.csv')\n",
    "print('Nb of rows of movies lmdb:')\n",
    "print(len(movies_lmdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_lmdb.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca5a65",
   "metadata": {},
   "source": [
    "Let's perform a content-based filtering on the overview informations (brief description of the movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_lmdb['overview'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_lmdb['overview'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english') # Principal Component Analysis PCA 20978 => 10 dimensions + 30 \n",
    "\n",
    "# Replace NaN with an empty string\n",
    "movies_lmdb['overview'] = movies_lmdb['overview'].fillna('')\n",
    "\n",
    "# Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(movies_lmdb['overview'])\n",
    "\n",
    "# Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape\n",
    "\n",
    "print(f'Nb of movies: {tfidf_matrix.shape[0]}  Nb of text features: {tfidf_matrix.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4843f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix) #=> 40 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90155f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas series\n",
    "indices = pd.Series(movies_lmdb.index, index=movies_lmdb['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec17f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations(title, cosine_sim=cosine_sim, top_k_movies=10):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the top k similar movies\n",
    "    sim_scores = sim_scores[1:(top_k_movies+1)]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return movies_lmdb['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b87cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('The Dark Knight Rises')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57401c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('Avatar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9318d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
